{
  "metadata" : {
    "config" : {
      "dependencies" : {
        "scala" : [
          "io.confluent:kafka-avro-serializer:5.3.1",
          "org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.4",
          "za.co.absa:abris_2.11:3.1.1",
          "org.apache.spark:spark-avro_2.11:2.4.4"
        ]
      },
      "exclusions" : [
      ],
      "repositories" : [
        {
          "maven" : {
            "base" : "http://packages.confluent.io/maven/"
          }
        }
      ],
      "sparkConfig" : {
        "spark.master" : "local[*]"
      }
    }
  },
  "nbformat" : 4,
  "nbformat_minor" : 0,
  "cells" : [
    {
      "cell_type" : "markdown",
      "execution_count" : 0,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "# spotter\n",
        "\n",
        "This is a text cell. Start editing!"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 1,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1579128909690,
          "endTs" : 1579128910054
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val schemaRegistryURL = \"http://schema-registry:8081\"\n",
        "val topic = \"spot-price-topic\""
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 2,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1579128911988,
          "endTs" : 1579128912669
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val df = spark.read\n",
        "        .format(\"kafka\")\n",
        "        .option(\"kafka.bootstrap.servers\", \"broker:29092\")\n",
        "        .option(\"subscribe\", topic)\n",
        "        .option(\"startingOffsets\", \"earliest\") // From starting\n",
        "        .load()\n",
        "df.printSchema"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "root\n",
            " |-- key: binary (nullable = true)\n",
            " |-- value: binary (nullable = true)\n",
            " |-- topic: string (nullable = true)\n",
            " |-- partition: integer (nullable = true)\n",
            " |-- offset: long (nullable = true)\n",
            " |-- timestamp: timestamp (nullable = true)\n",
            " |-- timestampType: integer (nullable = true)\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 3,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1579125981093,
          "endTs" : 1579125981358
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "import io.confluent.kafka.schemaregistry.client.CachedSchemaRegistryClient\n",
        "\n",
        "val schemaRegistryClient = new CachedSchemaRegistryClient(schemaRegistryURL, 128)\n",
        "\n",
        "val valueSchema = schemaRegistryClient.getLatestSchemaMetadata(topic + \"-value\").getSchema\n",
        "\n",
        "println(valueSchema)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "{\"type\":\"record\",\"name\":\"SpotPrice\",\"namespace\":\"io.github.ahappypie.spotter\",\"fields\":[{\"name\":\"provider\",\"type\":\"string\"},{\"name\":\"zone\",\"type\":\"string\"},{\"name\":\"instance\",\"type\":\"string\"},{\"name\":\"timestamp\",\"type\":{\"type\":\"long\",\"logicalType\":\"timestamp-millis\"}},{\"name\":\"price\",\"type\":\"double\"}]}\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 4,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1579125984645,
          "endTs" : 1579125985131
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "import org.apache.spark.sql.avro._\n",
        "import org.apache.spark.sql.types.DataTypes\n",
        "val avroDf = df.select(\n",
        "  'key.cast(DataTypes.StringType),\n",
        "  from_avro('value, valueSchema).as(\"value\")\n",
        ")"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 5,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1579125986508,
          "endTs" : 1579125986647
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "avroDf.printSchema"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "root\n",
            " |-- key: string (nullable = true)\n",
            " |-- value: struct (nullable = true)\n",
            " |    |-- provider: string (nullable = false)\n",
            " |    |-- zone: string (nullable = false)\n",
            " |    |-- instance: string (nullable = false)\n",
            " |    |-- timestamp: timestamp (nullable = false)\n",
            " |    |-- price: double (nullable = false)\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 6,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1579128917416,
          "endTs" : 1579128920938
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "import za.co.absa.abris.avro.functions.from_confluent_avro\n",
        "import za.co.absa.abris.avro.read.confluent.SchemaManager\n",
        "\n",
        "val schemaRegistryConfig = Map(\n",
        "  SchemaManager.PARAM_SCHEMA_REGISTRY_URL          -> schemaRegistryURL,\n",
        "  SchemaManager.PARAM_SCHEMA_REGISTRY_TOPIC        -> topic,\n",
        "  SchemaManager.PARAM_VALUE_SCHEMA_NAMING_STRATEGY -> SchemaManager.SchemaStorageNamingStrategies.TOPIC_NAME, // choose a subject name strategy\n",
        "  SchemaManager.PARAM_VALUE_SCHEMA_ID              -> \"latest\" // set to \"latest\" if you want the latest schema version to used  \n",
        ")\n",
        "\n",
        "val data = df.select(from_confluent_avro(col(\"value\"), schemaRegistryConfig) as 'data).select(\"data.*\")\n",
        "data.printSchema"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "root\n",
            " |-- provider: string (nullable = true)\n",
            " |-- zone: string (nullable = true)\n",
            " |-- instance: string (nullable = true)\n",
            " |-- timestamp: timestamp (nullable = true)\n",
            " |-- price: double (nullable = true)\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 7,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1579127565904,
          "endTs" : 1579127566109
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "data.select(col(\"zone\"), col(\"instance\"), col(\"price\"), col(\"timestamp\"))"
      ],
      "outputs" : [
        {
          "execution_count" : 7,
          "data" : {
            "text/plain" : [
              "[zone: string, instance: string ... 2 more fields]"
            ]
          },
          "metadata" : {
            "name" : "Out",
            "type" : "DataFrame"
          },
          "output_type" : "execute_result"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 8,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1579128933027,
          "endTs" : 1579128937887
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "data.createOrReplaceTempView(\"data\")\n",
        "spark.sql(\"select instance, min(price), avg(price), max(price), std(price) from data group by instance order by instance asc\")//.show(20, false)"
      ],
      "outputs" : [
        {
          "execution_count" : 8,
          "data" : {
            "text/plain" : [
              "[instance: string, min(price): double ... 3 more fields]"
            ]
          },
          "metadata" : {
            "name" : "Out",
            "type" : "DataFrame"
          },
          "output_type" : "execute_result"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 9,
      "metadata" : {
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
      ],
      "outputs" : [
      ]
    }
  ]
}